{"cells":[{"cell_type":"markdown","metadata":{"id":"hCmhmeOtEfdY"},"source":["# Neural Network - 2 tier approach\n","\n","embeddings -> brand classification"]},{"cell_type":"markdown","metadata":{"id":"726YkiX2EfdY"},"source":["### Imports and configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QG7o7kJEfdY","outputId":"0959e1ad-883a-405c-98b8-b08398baa013"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using GPU\n"]}],"source":["import torch\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"Using GPU\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Using CPU\")\n","\n","# device = torch.device(\"cpu\")  # Debugging purposes - easier to debug with CPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gcktdf9BEfdZ"},"outputs":[],"source":["from datetime import datetime\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import pickle\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim"]},{"cell_type":"markdown","metadata":{"id":"tXyO-c5_EfdZ"},"source":["### Load data from pkl file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53WNWNTaEfdZ"},"outputs":[],"source":["class SimpleDataset(Dataset):\n","    def __init__(self, features, labels):\n","        self.features = torch.tensor(features, dtype=torch.float32)\n","        self.labels = torch.tensor(labels, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.features[idx], self.labels[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztOjxqPOEfdZ"},"outputs":[],"source":["folder_to_save_products_embeddings = \"Tier_approach_logs_performacne\"\n","train_embeddings = os.path.join(folder_to_save_products_embeddings, 'train_set_embeddings.pkl')\n","test_embeddings = os.path.join(folder_to_save_products_embeddings, 'test_set_embeddings.pkl')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zzu_7lx7EfdZ","outputId":"809258fa-3c4c-4f9d-f48a-5a2bce0df17f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Embeddings shape: torch.Size([87672, 1768])\n","number of Unique brands: 3892\n","max brand class:  tensor(3891)\n","min brand class:  tensor(0)\n","train_y_brand.shape: torch.Size([87672])\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Austin\\AppData\\Local\\Temp\\ipykernel_3812\\2680378259.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.labels = torch.tensor(labels, dtype=torch.float32)\n"]}],"source":["BATCH_SIZE = 16\n","\n","# CHANGE COLUMN NAMES AS NEEDED TO LOAD DATA:\n","\n","# Load embeddings and labels from the pickle file\n","with open(train_embeddings, 'rb') as f:\n","    data = pickle.load(f)\n","    loaded_embeddings = data['embeddings']\n","    loaded_master_labels = data['master_labels']\n","    loaded_sub_labels = data['sub_labels']\n","    loaded_brand_labels = data['brand_labels']\n","\n","train_data = loaded_embeddings\n","\n","if isinstance(train_data, torch.Tensor):\n","    train_data = train_data.detach().cpu().numpy()  # Convert to NumPy array\n","\n","if isinstance(loaded_brand_labels, np.ndarray):\n","    loaded_brand_labels = torch.from_numpy(loaded_brand_labels)  # Convert to tensor\n","\n","mapped_labels = False\n","if int(max(set(loaded_brand_labels)) + 1) != len(loaded_brand_labels.unique()):\n","    # Check if the mapping is off\n","    print(f'max label: {max(set(loaded_brand_labels))}, num of unique labels: {len(loaded_brand_labels.unique())} - remapping labels...')\n","    unique_labels = torch.unique(loaded_brand_labels)\n","    label_mapping = {old_label.item(): new_label for new_label, old_label in enumerate(unique_labels)}\n","    loaded_brand_labels = loaded_brand_labels.clone().apply_(lambda x: label_mapping[x])\n","    mapped_labels = True\n","\n","train_num_brands = len(loaded_brand_labels.unique())\n","train_y_brand = loaded_brand_labels.cpu()\n","\n","# Print to verify the loaded data\n","print(\"Embeddings shape:\", loaded_embeddings.shape)  # Should show the shape of the embeddings\n","print(\"number of Unique brands:\", train_num_brands)\n","print('max brand class: ', max(loaded_brand_labels))\n","print('min brand class: ', min(loaded_brand_labels))\n","print(\"train_y_brand.shape:\", train_y_brand.shape)\n","\n","brand_dataset_train = SimpleDataset(train_data, train_y_brand)\n","brand_dataloader_train = DataLoader(brand_dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PwHA78AEEfda","outputId":"a2a112ee-7eba-47bf-df77-e80dd028f0a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Embeddings shape: torch.Size([21919, 1768])\n","number of Unique brands: 3136\n","max brand:  tensor(3891)\n","min brand:  tensor(1)\n","test_y_brand.shape: torch.Size([21919])\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Austin\\AppData\\Local\\Temp\\ipykernel_3812\\2680378259.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.labels = torch.tensor(labels, dtype=torch.float32)\n"]}],"source":["# Load embeddings and labels from the pickle file\n","\n","with open(test_embeddings, 'rb') as f:\n","    data = pickle.load(f)\n","    loaded_embeddings = data['embeddings']\n","    loaded_master_labels = data['master_labels']\n","    loaded_sub_labels = data['sub_labels']\n","    loaded_brand_labels = data['brand_labels']\n","\n","test_data = loaded_embeddings\n","\n","if isinstance(test_data, torch.Tensor):\n","    test_data = test_data.detach().cpu().numpy()  # Convert to NumPy array\n","\n","if isinstance(loaded_brand_labels, np.ndarray):\n","    loaded_brand_labels = torch.from_numpy(loaded_brand_labels)  # Convert to tensor\n","\n","if mapped_labels:\n","    # Apply the same label mapping to the test set if needed\n","    loaded_brand_labels = loaded_brand_labels.clone().apply_(lambda x: label_mapping.get(x, -1))\n","\n","test_y_brand = loaded_brand_labels.cpu()\n","\n","# Print to verify the loaded data\n","print(\"Embeddings shape:\", loaded_embeddings.shape)  # Should show the shape of the embeddings\n","print(\"number of Unique brands:\", len(loaded_brand_labels.unique()))\n","print('max brand: ', max(loaded_brand_labels))\n","print('min brand: ', min(loaded_brand_labels))\n","print(\"test_y_brand.shape:\", test_y_brand.shape)\n","\n","\n","brand_dataset_test = SimpleDataset(test_data, test_y_brand)\n","brand_dataloader_test = DataLoader(brand_dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3TQ8EztsEfda","outputId":"824babd6-b396-493d-8a2d-8cffda245403"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train data (embeddings) shape: (87672, 1768)\n","Test data (embeddigs) shape: (21919, 1768)\n","Train label (brand) shape:  torch.Size([87672])\n","Test label (brand) shape:  torch.Size([21919])\n"]}],"source":["print(\"Train data (embeddings) shape:\", train_data.shape)\n","print(\"Test data (embeddigs) shape:\", test_data.shape)\n","print('Train label (brand) shape: ', train_y_brand.shape)\n","print('Test label (brand) shape: ', test_y_brand.shape)"]},{"cell_type":"markdown","metadata":{"id":"s-0cwxIrEfda"},"source":["# Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0lBmh3wEfda"},"outputs":[],"source":["class brandClassifierNN(nn.Module):\n","    def __init__(self, input_size, output_size, layer1=64, layer2=32, dropout_rate=0.2, lr=0.001):\n","        super(brandClassifierNN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, layer1)  # First hidden layer\n","        self.dropout1 = nn.Dropout(dropout_rate)   # Dropout layer after first hidden layer\n","        self.fc2 = nn.Linear(layer1, layer2)        # Second hidden layer\n","        self.dropout2 = nn.Dropout(dropout_rate)   # Dropout layer after second hidden layer\n","        self.fc3 = nn.Linear(layer2, output_size)   # Output layer\n","        self.relu = nn.ReLU()                       # Activation function\n","        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n","        self.criterion = nn.CrossEntropyLoss()\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout1(x)  # Apply dropout after the first layer\n","        x = self.relu(self.fc2(x))\n","        x = self.dropout2(x)  # Apply dropout after the second layer\n","        x = self.fc3(x)\n","        return x\n","\n","    def train_model(self, train_dataloader, val_dataloader, optimizer=None, num_epochs=100, k=10, save_directory=None, log_file=None):\n","        if save_directory:\n","            os.makedirs(save_directory, exist_ok=True)  # Create directory if it doesn't exist\n","\n","        if optimizer is None:\n","            optimizer = self.optimizer\n","        self.train()  # Set the model to training mode\n","        for epoch in range(num_epochs):\n","            for features, labels in train_dataloader:\n","                optimizer.zero_grad()  # Clear gradients\n","                features = features.to(device)\n","                labels = labels.to(device)\n","\n","                # Forward pass\n","                logits = self(features)\n","                labels = labels.long()\n","                loss = self.criterion(logits, labels)  # Reshape if needed\n","\n","                # Backward pass\n","                loss.backward()\n","                optimizer.step()  # Update weights\n","\n","            if epoch % k == 0 or epoch == num_epochs - 1:\n","                # Evaluate on validation set\n","                _, val_loss, val_accuracy, strict_val_accuracy = self.evaluate(val_dataloader)\n","                self.train()\n","\n","                log_message = (f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, \"\n","                           f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, \"\n","                           f\"99% Accuracy: {strict_val_accuracy:.4f}\")\n","                print(log_message)\n","\n","                # If a log file is specified, append to it\n","                if save_directory:\n","                    if log_file:\n","                        log_path = os.path.join(save_directory, log_file)\n","\n","                        if log_path.endswith(\".txt\"):  # Ensure it's a text file\n","                            with open(log_path, \"a\") as f:  # Open in append mode\n","                                f.write(log_message + \"\\n\")\n","                        else:\n","                            print(\"Warning: Provided file is not a .txt file, skipping logging.\")\n","                    file_name = os.path.join(save_directory, f\"model.pth\")\n","                    # Save the model\n","                    torch.save(self, file_name)\n","\n","        return val_loss\n","\n","    def evaluate(self, dataloader, device=device):\n","        self.eval()  # Set the model to evaluation mode\n","        total_loss = 0\n","        correct_predictions = 0\n","        strict_correct_predictions = 0\n","        total_samples = 0\n","        all_logits = []\n","\n","        with torch.no_grad():  # No need to track gradients\n","            for features, labels in dataloader:\n","                features = features.to(device)\n","                labels = labels.to(device)\n","\n","                # Forward pass\n","                logits = self(features)  # Get the raw logits\n","                all_logits.append(logits.cpu())\n","                labels = labels.long()\n","\n","                # Compute loss\n","                loss = self.criterion(logits, labels)\n","                total_loss += loss.item()\n","\n","                # Calculate accuracy\n","                probabilities = torch.softmax(logits, dim=1)\n","                predictions = torch.argmax(probabilities, axis=1)\n","                correct_predictions += (predictions == labels).sum().item()\n","\n","                strict_predictions = (probabilities.max(dim=1).values >= 0.99) & (predictions == labels)\n","                strict_correct_predictions += strict_predictions.sum().item()\n","\n","                total_samples += labels.size(0)\n","\n","        all_logits = torch.cat(all_logits, dim=0)\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = correct_predictions / total_samples\n","        strict_accuracy = strict_correct_predictions / total_samples\n","        return all_logits, avg_loss, accuracy, strict_accuracy"]},{"cell_type":"markdown","metadata":{"id":"qCGMv-xtEfda"},"source":["### Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5nFVce4Efda"},"outputs":[],"source":["def random_search(train_loader, val_loader, n_trials=10, epochs=10, k=5):\n","    best_model = None\n","    best_loss = float('inf')\n","    best_params = {}\n","\n","    for i in range(n_trials):\n","\n","        # CHANGE SEARCH PARAMETERS AS NEEDED:\n","\n","        layer1 = np.random.randint(64, 1024)\n","        layer2 = np.random.randint(32, 1024)\n","        dropout_rate = np.random.uniform(0.05, 0.4)\n","        learning_rate = 10**np.random.uniform(-6, -2)\n","\n","        # layer1 = np.random.randint(32, 128)  # Number of neurons in first layer\n","        # layer2 = np.random.randint(16, 64)   # Number of neurons in second layer\n","        # dropout_rate = np.random.uniform(0.1, 0.5)  # Dropout rate\n","        # learning_rate = 10**np.random.uniform(-5, 0)  # Learning rate\n","\n","        print(f'--- Params (iter {i+1}) ---')\n","        print(f'layer1: {layer1}, layer2: {layer2}, dropout: {dropout_rate}, learning_rate: {learning_rate}')\n","\n","        # Initialize model, loss function, and optimizer\n","        embedding_size = train_data.shape[1]\n","        model = brandClassifierNN(embedding_size, train_num_brands, layer1=layer1, layer2=layer2, dropout_rate=dropout_rate)\n","        model.to(device)\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","        # Train model\n","        val_loss = model.train_model(train_dataloader=train_loader, val_dataloader=val_loader, optimizer=optimizer, num_epochs=epochs, k=k)\n","\n","        # Update best model if current one is better\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            best_model = model\n","            best_params = {'layer1': layer1, 'layer2': layer2, 'dropout_rate': dropout_rate, 'learning_rate': learning_rate}\n","\n","    return best_model, best_params, best_loss\n"]},{"cell_type":"markdown","metadata":{"id":"9OC6y0-qEfdb"},"source":["### Neural Network Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YiFQT8ElEfdb","outputId":"94b734fb-b8d9-4890-c871-624fb2e12d36"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Params (iter 0) ---\n","layer1: 823, layer2: 150, dropout: 0.2384689883394433, learning_rate: 0.002335975404451696\n","Epoch [1/1], Loss: 5.4217, Val Loss: 5.5983, Val Accuracy: 0.0939, 99% Accuracy: 0.0121\n","Best Loss: 5.598326482215937\n","Best Hyperparameters: {'layer1': 823, 'layer2': 150, 'dropout_rate': 0.2384689883394433, 'learning_rate': 0.002335975404451696}\n","Number of learnable weights: 2167179\n","Epoch [1/5], Loss: 6.4838, Val Loss: 5.8245, Val Accuracy: 0.1002, 99% Accuracy: 0.0183\n","Epoch [2/5], Loss: 6.7148, Val Loss: 5.6035, Val Accuracy: 0.1011, 99% Accuracy: 0.0326\n","Epoch [3/5], Loss: 5.8328, Val Loss: 5.6515, Val Accuracy: 0.0910, 99% Accuracy: 0.0317\n","Epoch [4/5], Loss: 5.0018, Val Loss: 5.6073, Val Accuracy: 0.0911, 99% Accuracy: 0.0334\n","Epoch [5/5], Loss: 5.7651, Val Loss: 5.5462, Val Accuracy: 0.1022, 99% Accuracy: 0.0411\n"]}],"source":["# Hyperparam tuning\n","best_model, best_params, best_loss = random_search(brand_dataloader_train, brand_dataloader_test, n_trials=6, epochs=5, k=1)\n","\n","print(f'Best Loss: {best_loss}')\n","print(f'Best Hyperparameters: {best_params}')\n","\n","\n","# Initialize model\n","logfilepath = \"logs.txt\"\n","current_time = datetime.now().strftime(\"%Y-%m-%d_%I-%M_%p\")\n","train_log_title = 'Filename' #TODO: INSERT FILE NAME HERE\n","title = train_log_title + \"_\" if train_log_title else ''\n","save_directory = f\"{title}train_logs_{current_time}\"\n","\n","embedding_size = train_data.shape[1]\n","\n","# Can also manually set number of nodes and parameters. For example:\n","# model_brand = brandClassifierNN(embedding_size, train_num_brands, layer1=249, layer2=433, dropout_rate=0.12155841326717244, lr=0.00008654271868553579)\n","\n","model_brand = brandClassifierNN(\n","    embedding_size,\n","    train_num_brands,\n","    layer1=best_params['layer1'],\n","    layer2=best_params['layer2'],\n","    dropout_rate=best_params['dropout_rate'],\n","    lr=best_params['learning_rate']\n","    )\n","\n","model_brand.to(device)\n","num_weights = sum(p.numel() for p in model_brand.parameters() if p.requires_grad)\n","print(f\"Number of learnable weights: {num_weights}\")\n","\n","\n","# Train the model\n","\n","# For enabling training logs:\n","model_brand.train_model(brand_dataloader_train, brand_dataloader_test, num_epochs=50, k=1, save_directory=save_directory, log_file=logfilepath)\n","\n","# For disabling traning logs:\n","# model_brand.train_model(brand_dataloader_train, brand_dataloader_test, num_epochs=50, k=1)\n","\n","logits_brand, loss_brand, accuracy_brand, strict_accuracy_brand = model_brand.evaluate(brand_dataloader_test)\n","logits_brand = logits_brand.cpu().numpy()\n"]},{"cell_type":"markdown","metadata":{"id":"QYylahGqEfdb"},"source":["### Neural Network Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXBSJzbjEfdb","outputId":"fd87b5ea-d639-4e2e-ebd8-00937a2cfc18"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Austin\\anaconda3\\envs\\condaenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"name":"stdout","output_type":"stream","text":["\n","--- TestTest_brand_ Default Metrics ---\n","Accuracy: 0.102\n","Precision: 0.011\n","Recall: 0.012\n","F1 Score: 0.012\n","Adjusted Accuracy: 0.102\n","Image Coverage: 1.0\n","Brand Coverage: 0.03\n","\n","--- TestTest_brand_ 95% Metrics ---\n","Accuracy: 0.045\n","Precision: 0.009\n","Recall: 0.006\n","F1 Score: 0.007\n","Adjusted Accuracy: 0.986\n","Image Coverage: 0.045\n","Brand Coverage: 0.01\n","\n","--- TestTest_brand_ 96% Metrics ---\n","Accuracy: 0.044\n","Precision: 0.009\n","Recall: 0.005\n","F1 Score: 0.007\n","Adjusted Accuracy: 0.987\n","Image Coverage: 0.044\n","Brand Coverage: 0.01\n","\n","--- TestTest_brand_ 97% Metrics ---\n","Accuracy: 0.043\n","Precision: 0.009\n","Recall: 0.005\n","F1 Score: 0.007\n","Adjusted Accuracy: 0.986\n","Image Coverage: 0.044\n","Brand Coverage: 0.009\n","\n","--- TestTest_brand_ 98% Metrics ---\n","Accuracy: 0.042\n","Precision: 0.009\n","Recall: 0.005\n","F1 Score: 0.007\n","Adjusted Accuracy: 0.986\n","Image Coverage: 0.043\n","Brand Coverage: 0.009\n","\n","--- TestTest_brand_ 99% Metrics ---\n","Accuracy: 0.041\n","Precision: 0.009\n","Recall: 0.005\n","F1 Score: 0.006\n","Adjusted Accuracy: 0.987\n","Image Coverage: 0.042\n","Brand Coverage: 0.009\n","Metrics and definitions saved to TestTest_train_logs_2024-11-12_01-35_AM\\TestTest_brand_metrics_output.xlsx\n"]}],"source":["def get_threshold_metrics(logits, y_true, threshold=None):\n","    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()\n","    y_pred = np.argmax(logits, axis=1)\n","\n","    unique_images_test = len(y_true)  # Unique images in the test set\n","    unique_brands_test = len(np.unique(y_true))  # Unique brands in the test set\n","\n","    if threshold:\n","        predicted_probabilities = probs[np.arange(len(probs)), y_pred]\n","        y_pred_threshold = np.where(predicted_probabilities >= threshold, y_pred, -1)\n","\n","        accuracy = accuracy_score(y_true, y_pred_threshold)\n","        precision = precision_score(y_true, y_pred_threshold, average='macro', zero_division=0)\n","        recall = recall_score(y_true, y_pred_threshold, average='macro', zero_division=0)\n","        f1 = (2 * precision * recall) / (precision + recall) if (precision+recall>0) else 0.0\n","\n","        valid_indices = predicted_probabilities >= threshold  # Get indices where predictions meet the threshold\n","        y_pred_adj =  y_pred_threshold[valid_indices]\n","        adj_accuracy = accuracy_score(y_true[valid_indices], y_pred_adj) if np.any(valid_indices) else 0.0\n","        unique_images_pred = len(y_pred_adj)\n","        unique_brands_pred = len(np.unique(y_pred_adj))\n","\n","    else:\n","        accuracy = accuracy_score(y_true, y_pred)\n","        precision = precision_score(y_true, y_pred, average='macro')\n","        recall = recall_score(y_true, y_pred, average='macro')\n","        f1 = (2 * precision * recall) / (precision + recall)\n","        adj_accuracy = accuracy\n","        unique_images_pred = len(y_pred)\n","        unique_brands_pred = len(np.unique(y_pred))\n","\n","    coverage_images = unique_images_pred / unique_images_test if unique_images_test > 0 else 0.0\n","    coverage_brands = unique_brands_pred / unique_brands_test if unique_brands_test > 0 else 0.0\n","\n","    return accuracy, precision, recall, f1, adj_accuracy, coverage_images, coverage_brands\n","\n","\n","def evaluate_and_save_model_stats(logits, y_true, metrics_title, file_path=None, print_metrics=False):\n","    # Dictionary to store metrics for each threshold\n","    metrics_dict = {\n","        \"Threshold\": [],\n","        \"Accuracy\": [],\n","        \"Precision\": [],\n","        \"Recall\": [],\n","        \"F1 Score\": [],\n","        \"Adjusted Accuracy\": [],\n","        \"Image Coverage\": [],\n","        \"Brand Coverage\": []\n","    }\n","\n","    # Evaluate metrics at default, 99%, and 95% thresholds\n","    for threshold, label in [(None, \"Default\"), (0.95, \"95%\"), (0.96, \"96%\"), (0.97, \"97%\"), (0.98, \"98%\"), (0.99, \"99%\")]:\n","        accuracy, precision, recall, f1, adj_accuracy, cov_img, cov_brand = get_threshold_metrics(logits, y_true, threshold)\n","\n","        accuracy = round(accuracy, 3)\n","        precision = round(precision, 3)\n","        recall = round(recall, 3)\n","        f1 = round(f1, 3)\n","        adj_accuracy = round(adj_accuracy, 3)\n","        cov_img = round(cov_img, 3)\n","        cov_brand = round(cov_brand, 3)\n","\n","        if print_metrics:\n","            # Print metrics to console\n","            print(f'\\n--- {metrics_title} {label} Metrics ---')\n","            print(f'Accuracy: {accuracy}')\n","            print(f'Precision: {precision}')\n","            print(f'Recall: {recall}')\n","            print(f'F1 Score: {f1}')\n","            print(f'Adjusted Accuracy: {adj_accuracy}')\n","            print(f'Image Coverage: {cov_img}')\n","            print(f'Brand Coverage: {cov_brand}')\n","\n","            # Store metrics in dictionary\n","            metrics_dict[\"Threshold\"].append(label)\n","            metrics_dict[\"Accuracy\"].append(accuracy)\n","            metrics_dict[\"Precision\"].append(precision)\n","            metrics_dict[\"Recall\"].append(recall)\n","            metrics_dict[\"F1 Score\"].append(f1)\n","            metrics_dict[\"Adjusted Accuracy\"].append(adj_accuracy)\n","            metrics_dict[\"Image Coverage\"].append(cov_img)\n","            metrics_dict[\"Brand Coverage\"].append(cov_brand)\n","\n","    if file_path:\n","        metrics_df = pd.DataFrame(metrics_dict)\n","\n","        definitions = {\n","        \"Metric\": [\n","            \"Softmax Threshold\",\n","            \"Accuracy\",\n","            \"Adjusted Accuracy\",\n","            \"Coverage_images\",\n","            \"Coverage_brands\"\n","        ],\n","        \"Definition\": [\n","            \"No threshold: all images are used. 99% threshold: predictions meeting at least 99% softmax probability.\",\n","            \"Number of predictions meeting the threshold and are correct / test set size.\",\n","            \"Number of predictions meeting the threshold and are correct / Number of predictions meeting the threshold.\",\n","            \"Unique images meeting the threshold / unique images in test set.\",\n","            \"Unique brands meeting the threshold / unique brands in test set.\"\n","        ],\n","        \"Example\": [\n","            \"100 images with 85 unique brands. Model classified 90 images correctly with no threshold. 80 images (55 unique brands) meet the 99% threshold, out of these 80 images 75 were classified correctly.\",\n","            \"No threshold accuracy: 0.90, 99% threshold accuracy: 0.75\",\n","            \"99% adjusted accuracy: 75/80 = 0.93\",\n","            \"99% Coverage_Images: 0.80\",\n","            \"99% Coverage_brands: 55/85 = 0.647\"\n","        ]\n","        }\n","        definitions_df = pd.DataFrame(definitions)\n","\n","\n","        with pd.ExcelWriter(file_path) as writer:\n","            metrics_df.to_excel(writer, sheet_name=\"Metrics\", index=False)\n","            definitions_df.to_excel(writer, sheet_name=\"Definitions\", index=False)\n","\n","        print(f\"Metrics and definitions saved to {file_path}\")\n","\n","file_name = f\"{train_log_title}_brand\"\n","file_name = file_name + '_' if file_name else ''\n","file_path = f'{save_directory}\\\\{file_name}metrics_output.xlsx'\n","evaluate_and_save_model_stats(logits_brand, test_y_brand, metrics_title=file_name, file_path=file_path, print_metrics=True)\n"]}],"metadata":{"kernelspec":{"display_name":"condaenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}